#!/usr/bin/env julia

"""
Semi-Automated Evolution Script

LLMã¨ã®å”åƒã§é€²åŒ–è¨ˆç®—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    # åˆæœŸé›†å›£ç”Ÿæˆï¼ˆä¸–ä»£0ï¼‰
    julia --project=. semi_auto_evolution.jl --generate-initial --size 20
    
    # ä¸–ä»£Nã®è©•ä¾¡
    julia --project=. semi_auto_evolution.jl --evaluate N --input results/models_genN.json
"""

using ArgParse
using Printf

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èª­ã¿è¾¼ã¿
push!(LOAD_PATH, joinpath(@__DIR__, "src"))

include("src/Phase5/Phase5.jl")
include("src/evolution_utils.jl")

using .Phase5
using .EvolutionUtils
using Statistics

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
function parse_commandline()
    s = ArgParseSettings(
        description = "Semi-Automated Evolution for Wake Model Discovery"
    )
    
    @add_arg_table! s begin
        "--generate-initial"
            help = "Generate initial population feedback"
            action = :store_true
        "--size"
            help = "Population size for initial generation"
            arg_type = Int
            default = 20
        "--evaluate"
            help = "Evaluate generation N"
            arg_type = Int
            default = -1
        "--input"
            help = "Input JSON file with LLM-generated models"
            arg_type = String
            default = ""
        "--csv-path"
            help = "Path to CFD data CSV"
            arg_type = String
            default = "data/result_I0p3000_C22p0000.csv"
        "--exp-name"
            help = "Experiment name (creates results/{exp_name}/)"
            arg_type = String
            default = "default"
        "--seeds-file"
            help = "Path to seeds JSON file"
            arg_type = String
            default = "seeds.json"
    end
    
    return parse_args(s)
end


"""
    generate_initial(size::Int, exp_name::String, seeds_file::String)

åˆæœŸé›†å›£ï¼ˆä¸–ä»£0ï¼‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
"""
function generate_initial(size::Int, exp_name::String, seeds_file::String)
    println("\n" * "="^70)
    println("ğŸŒ± Generating Initial Population Feedback (Generation 0)")
    println("="^70)
    
    # resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    base_dir = joinpath("results", exp_name)
    mkpath(base_dir)
    mkpath(joinpath(base_dir, "plots"))

    # ã‚·ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    seeds = EvolutionUtils.load_seeds(seeds_file)
    if !isempty(seeds)
        println("   âœ“ Loaded $(length(seeds)) seed models from $seeds_file")
        println("   â„¹ï¸  Using these seeds to initialize the population.")
    else
        println("   â„¹ï¸  No seeds loaded (starting fresh)")
    end
    
    # åˆæœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
    feedback_path = joinpath(base_dir, "feedback_gen0.json")
    EvolutionUtils.generate_initial_feedback(size, feedback_path; seeds=seeds)
    
    println("\nâœ… Initial feedback generated!")
    println("\nğŸ“‹ Next steps:")
    println("   1. View feedback: cat $feedback_path")
    println("   2. Give the feedback to Gemini LLM")
    println("   3. Save Gemini's response to: $(joinpath(base_dir, "models_gen1.json"))")
    println("   4. Run: julia --project=. semi_auto_evolution.jl --evaluate 1 --input $(joinpath(base_dir, "models_gen1.json")) --exp-name $exp_name")
    println()
end

"""
    evaluate_generation(gen::Int, input_file::String, csv_path::String, exp_name::String)

æŒ‡å®šä¸–ä»£ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
"""
function evaluate_generation(gen::Int, input_file::String, csv_path::String, exp_name::String)
    println("\n" * "="^70)
    println("ğŸ”¬ Evaluating Generation $gen")
    println("="^70)
    
    # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    println("\nğŸ“‚ Loading models from: $input_file")
    models = EvolutionUtils.load_models(input_file)
    
    if isempty(models)
        error("No models found in input file!")
    end
    
    # Load prompt template
    template_path = "templates/phase5_prompt.md"
    if !isfile(template_path)
        # Fallback for backward compatibility if renamed
        if isfile("templates/llm_prompt_template.md")
             template_path = "templates/llm_prompt_template.md"
        else
             error("Prompt template not found: $template_path")
        end
    end
    prompt_template = read(template_path, String)
    println("\nâš™ï¸  Evaluating models...")
    evaluated = []
    
    for (i, m) in enumerate(models)
        @printf "   [%2d/%2d] " i length(models)
        print("$(m.model[1:min(40, length(m.model))])... ")
        
        try
            score, Î¸ = Phase5.evaluate_formula(
                m.model;
                num_coeffs=m.num_coeffs,
                with_penalty=true,
                csv_path=csv_path
            )
            
            if Î¸ !== nothing && !isinf(score) && !isnan(score)
                push!(evaluated, (
                    id = m.id,
                    model = m.model,
                    score = score,
                    coeffs = Î¸,
                    reason = m.reason,
                    ep_type = m.ep_type,
                    parent_generation = m.parent_generation,
                    parent_id = m.parent_id
                ))
                @printf "âœ“ Score: %.6f\n" score
            else
                println("âœ— Failed")
            end
        catch e
            println("âœ— Error: $(typeof(e))")
        end
    end
    
    if isempty(evaluated)
        error("All models failed evaluation!")
    end
    
    println("\n   âœ“ Successfully evaluated: $(length(evaluated))/$(length(models)) models")
    
    # çµæœã‚’ã‚½ãƒ¼ãƒˆ
    sort!(evaluated, by=x->x.score)
    
    # çµ±è¨ˆè¡¨ç¤º
    println("\n" * "="^70)
    println("ğŸ“Š Generation $gen Statistics")
    println("="^70)
    println("   Population size: $(length(evaluated))")
    @printf "   Best score:      %.6f\n" evaluated[1].score
    @printf "   Median score:    %.6f\n" median([m.score for m in evaluated])
    @printf "   Mean score:      %.6f\n" mean([m.score for m in evaluated])
    @printf "   Worst score:     %.6f\n" evaluated[end].score
    
    # ãƒˆãƒƒãƒ—3ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
    println("\nğŸ† Top 3 Models:")
    println("-"^70)
    for (i, m) in enumerate(evaluated[1:min(3, length(evaluated))])
        println("\n[$i] Score: $(round(m.score, digits=6))")
        println("    Formula: $(m.model)")
        println("    Coeffs: $(round.(m.coeffs, digits=4))")
        if !isempty(m.reason)
            println("    Reason: $(m.reason)")
        end
    end
    
    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯JSONä¿å­˜
    base_dir = joinpath("results", exp_name)
    feedback_path = joinpath(base_dir, "feedback_gen$gen.json")
    EvolutionUtils.save_feedback(gen, evaluated, feedback_path)
    
    # å±¥æ­´ãƒ­ã‚°ã«è¿½è¨˜
    history_path = joinpath(base_dir, "history.jsonl")
    EvolutionUtils.append_history(gen, evaluated, history_path)
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º
    next_gen = gen + 1
    println("\n" * "="^70)
    println("âœ… Evaluation Complete!")
    println("="^70)
    println("\nğŸ“‹ Next steps:")
    println("   1. View feedback: cat $feedback_path")
    println("   2. Give the feedback to Gemini LLM")
    println("   3. Save Gemini's response to: $(joinpath(base_dir, "models_gen$next_gen.json"))")
    println("   4. Run: julia --project=. semi_auto_evolution.jl --evaluate $next_gen --input $(joinpath(base_dir, "models_gen$next_gen.json")) --exp-name $exp_name")
    println("\nğŸ’¡ To visualize progress: julia --project=. visualize_evolution.jl --exp-name $exp_name")
    println()
end

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
function main()
    args = parse_commandline()
    
    if args["generate-initial"]
        # åˆæœŸé›†å›£ç”Ÿæˆ
        generate_initial(args["size"], args["exp-name"], args["seeds-file"])
        
    elseif args["evaluate"] > 0
        # ä¸–ä»£ã®è©•ä¾¡
        input_file = args["input"]
        if isempty(input_file)
            # inputãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ç”Ÿæˆ
            # results/{exp_name}/models_gen{gen}.json
            input_file = joinpath("results", args["exp-name"], "models_gen$(args["evaluate"]).json")
            println("â„¹ï¸  Input file not specified. Using default: $input_file")
        end
        
        evaluate_generation(
            args["evaluate"],
            input_file,
            args["csv-path"],
            args["exp-name"]
        )
        
    else
        println("Error: Either --generate-initial or --evaluate must be specified")
        println("Run with --help for usage information")
        exit(1)
    end
end

# å®Ÿè¡Œ
if abspath(PROGRAM_FILE) == @__FILE__
    main()
end
