#!/usr/bin/env julia

"""
Semi-Automated Evolution Script

LLMã¨ã®å”åƒã§é€²åŒ–è¨ˆç®—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    # åˆæœŸé›†å›£ç”Ÿæˆï¼ˆä¸–ä»£0ï¼‰
    julia --project=. semi_auto_evolution.jl --generate-initial --size 20
    
    # ä¸–ä»£Nã®è©•ä¾¡
    julia --project=. semi_auto_evolution.jl --evaluate N --input results/models_genN.json
"""

using ArgParse
using Printf

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èª­ã¿è¾¼ã¿
push!(LOAD_PATH, joinpath(@__DIR__, "src"))

include("src/Phase5.jl")
include("src/evolution_utils.jl")

using .Phase5
using .EvolutionUtils

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
function parse_commandline()
    s = ArgParseSettings(
        description = "Semi-Automated Evolution for Wake Model Discovery"
    )
    
    @add_arg_table! s begin
        "--generate-initial"
            help = "Generate initial population feedback"
            action = :store_true
        "--size"
            help = "Population size for initial generation"
            arg_type = Int
            default = 20
        "--evaluate"
            help = "Evaluate generation N"
            arg_type = Int
            default = -1
        "--input"
            help = "Input JSON file with LLM-generated models"
            arg_type = String
            default = ""
        "--csv-path"
            help = "Path to CFD data CSV"
            arg_type = String
            default = "data/result_I0p3000_C22p0000.csv"
    end
    
    return parse_args(s)
end


"""
    generate_initial(size::Int)

åˆæœŸé›†å›£ï¼ˆä¸–ä»£0ï¼‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
"""
function generate_initial(size::Int)
    println("\n" * "="^70)
    println("ğŸŒ± Generating Initial Population Feedback (Generation 0)")
    println("="^70)
    
    # resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    mkpath("results")
    mkpath("results/plots")
    
    # åˆæœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
    feedback_path = "results/feedback_gen0.json"
    EvolutionUtils.generate_initial_feedback(size, feedback_path)
    
    println("\nâœ… Initial feedback generated!")
    println("\nğŸ“‹ Next steps:")
    println("   1. View feedback: cat $feedback_path")
    println("   2. Give the feedback to Gemini LLM")
    println("   3. Save Gemini's response to: results/models_gen1.json")
    println("   4. Run: julia --project=. semi_auto_evolution.jl --evaluate 1 --input results/models_gen1.json")
    println()
end


"""
    evaluate_generation(gen::Int, input_file::String, csv_path::String)

æŒ‡å®šä¸–ä»£ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
"""
function evaluate_generation(gen::Int, input_file::String, csv_path::String)
    println("\n" * "="^70)
    println("ğŸ”¬ Evaluating Generation $gen")
    println("="^70)
    
    # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    println("\nğŸ“‚ Loading models from: $input_file")
    models = EvolutionUtils.load_models(input_file)
    
    if isempty(models)
        error("No models found in input file!")
    end
    
    println("   âœ“ Loaded $(length(models)) models")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®ç¢ºèª
    if !isfile(csv_path)
        error("Data file not found: $csv_path")
    end
    
    # å„ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
    println("\nâš™ï¸  Evaluating models...")
    evaluated = []
    
    for (i, m) in enumerate(models)
        @printf "   [%2d/%2d] " i length(models)
        print("$(m.model[1:min(40, length(m.model))])... ")
        
        try
            score, Î¸ = Phase5.evaluate_formula(
                m.model;
                num_coeffs=m.num_coeffs,
                with_penalty=false,
                csv_path=csv_path
            )
            
            if Î¸ !== nothing && !isinf(score) && !isnan(score)
                push!(evaluated, (
                    model = m.model,
                    score = score,
                    coeffs = Î¸,
                    reason = m.reason,
                    ep_type = m.ep_type
                ))
                @printf "âœ“ Score: %.6f\n" score
            else
                println("âœ— Failed")
            end
        catch e
            println("âœ— Error: $(typeof(e))")
        end
    end
    
    if isempty(evaluated)
        error("All models failed evaluation!")
    end
    
    println("\n   âœ“ Successfully evaluated: $(length(evaluated))/$(length(models)) models")
    
    # çµæœã‚’ã‚½ãƒ¼ãƒˆ
    sort!(evaluated, by=x->x.score)
    
    # çµ±è¨ˆè¡¨ç¤º
    println("\n" * "="^70)
    println("ğŸ“Š Generation $gen Statistics")
    println("="^70)
    println("   Population size: $(length(evaluated))")
    @printf "   Best score:      %.6f\n" evaluated[1].score
    @printf "   Median score:    %.6f\n" median([m.score for m in evaluated])
    @printf "   Mean score:      %.6f\n" mean([m.score for m in evaluated])
    @printf "   Worst score:     %.6f\n" evaluated[end].score
    
    # ãƒˆãƒƒãƒ—3ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
    println("\nğŸ† Top 3 Models:")
    println("-"^70)
    for (i, m) in enumerate(evaluated[1:min(3, length(evaluated))])
        println("\n[$i] Score: $(round(m.score, digits=6))")
        println("    Formula: $(m.model)")
        println("    Coeffs: $(round.(m.coeffs, digits=4))")
        if !isempty(m.reason)
            println("    Reason: $(m.reason)")
        end
    end
    
    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯JSONä¿å­˜
    feedback_path = "results/feedback_gen$gen.json"
    EvolutionUtils.save_feedback(gen, evaluated, feedback_path)
    
    # å±¥æ­´ãƒ­ã‚°ã«è¿½è¨˜
    history_path = "results/history.jsonl"
    EvolutionUtils.append_history(gen, evaluated, history_path)
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º
    next_gen = gen + 1
    println("\n" * "="^70)
    println("âœ… Evaluation Complete!")
    println("="^70)
    println("\nğŸ“‹ Next steps:")
    println("   1. View feedback: cat $feedback_path")
    println("   2. Give the feedback to Gemini LLM")
    println("   3. Save Gemini's response to: results/models_gen$next_gen.json")
    println("   4. Run: julia --project=. semi_auto_evolution.jl --evaluate $next_gen --input results/models_gen$next_gen.json")
    println("\nğŸ’¡ To visualize progress: julia --project=. visualize_evolution.jl")
    println()
end


# ãƒ¡ã‚¤ãƒ³å‡¦ç†
function main()
    args = parse_commandline()
    
    if args["generate-initial"]
        # åˆæœŸé›†å›£ç”Ÿæˆ
        generate_initial(args["size"])
        
    elseif args["evaluate"] > 0
        # ä¸–ä»£ã®è©•ä¾¡
        if isempty(args["input"])
            error("--input argument is required for evaluation")
        end
        
        evaluate_generation(
            args["evaluate"],
            args["input"],
            args["csv-path"]
        )
        
    else
        println("Error: Either --generate-initial or --evaluate must be specified")
        println("Run with --help for usage information")
        exit(1)
    end
end

# å®Ÿè¡Œ
if abspath(PROGRAM_FILE) == @__FILE__
    main()
end
